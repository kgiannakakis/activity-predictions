---
title: "Personal Activity Training Predictions"
author: "Kostas Giannakakis"
date: "16 January 2016"
output: html_document
---

##Executive Summary
Aim of this report is to recognize human activity from sensor values. The data come from [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har). Three different models are tried out and cross validation is used to select the best one. Accuracy metric is used to compare the model. It is found out that at least two models (Random Forests and Boosting) can predict the outcome with high accuracy.

##Prerequisites
The analysis uses the caret package.

```{r dependencies, warning=FALSE, message=FALSE}
library(caret)
```

##Cleaning data and features selection

We initially read the data and load them into data frames. There are two data sets. The first one will be used for training the models and the second one for doing predictions. The second one doesn't contain the outcome information and the results are only to be found by submitting the corresponding quiz in Coursera.

```{r load_data, cache=TRUE}
train <- read.csv("pml-training.csv", header=TRUE)
test <- read.csv("pml-testing.csv", header=TRUE)
```

After we have loaded the data, we need to select the features we are going to use for prediction. The first seven columns are removed, because they contain information that is obviously irrelevant with the human activity (person's name, time stamps). After that, we notice that many columns are empty and only contain NA values. These columns are removed and we are left with the outcome and 52 features. Although more analysis could be performed to further reduce this number, based on the contribution of each feature to the variability, the decision is made to use all of them to build the model. This will result with slower model training, but also to higher accuracy.

```{r cleaning_data, cache=TRUE}
trainP <- train[,-(1:7)]
testP <- test[,-(1:7)]

countNAs <- function(c) { sum(is.na(c)) }
nas <- sapply(testP, countNAs)

trainP <- trainP[, nas != 20]
testP <- testP[, nas != 20]
```

##Cross Validation

```{r data_sets, cache=TRUE}
trainIndex <- createDataPartition(y=trainP$classe, p=0.6, list=FALSE)
training <- trainP[trainIndex,]
testingValidation <- trainP[-trainIndex,]

testIndex <- createDataPartition(y=testingValidation$classe, p=0.5, list=FALSE)
testing <- testingValidation[testIndex,]
validation <- testingValidation[-testIndex,]
```

##Trees model

```{r model_trees, cache=TRUE}
timeTrees <- system.time(
  modelTrees <- train(classe ~ ., method="rpart", data=training)
)
cmTreesTraining <- confusionMatrix(training$classe, predict(modelTrees, training))
cmTreesTesting <- confusionMatrix(testing$classe, predict(modelTrees, testing))
```

##Random forests model

```{r model_rf, cache=TRUE}
timeRf <- system.time(
  modelRf <- train(classe ~ ., method="rf", data=training, prox=TRUE)
)
cmRfTraining <- confusionMatrix(training$classe, predict(modelRf, training))
cmRfTesting <- confusionMatrix(testing$classe, predict(modelRf, testing))
```

##Boosting model

```{r model_boosting, cache=TRUE, message=FALSE}
timeBoosting <- system.time(
  modelBoosting <- train(classe ~ ., method="gbm", data=training, verbose=FALSE)
)
cmBoostingTraining <- confusionMatrix(training$classe, predict(modelBoosting, training))
cmBoostingTesting <- confusionMatrix(testing$classe, predict(modelBoosting, testing))
```

##Results

```{r results}
results <- data.frame( train.accuracy = c(as.matrix(cmTreesTraining, what = "overall")[1,],
                                          as.matrix(cmRfTraining, what = "overall")[1,],
                                          as.matrix(cmBoostingTraining, what = "overall")[1,]),
                       test.accuracy = c(as.matrix(cmTreesTesting, what = "overall")[1,],
                                          as.matrix(cmRfTesting, what = "overall")[1,],
                                          as.matrix(cmBoostingTesting, what = "overall")[1,]),
                       time = c(timeTrees[[1]], timeRf[[1]], timeBoosting[[1]]))
row.names(results) <- c("Trees", "Random forests", "Boosting")
results

```

##Predictions
```{r out_of_sample_errors, message=FALSE, warning=FALSE}
cm <- confusionMatrix(testing$classe, predict(modelRf, validation))
cm
```

```{r predictions, warning=FALSE, message=FALSE}
predict(modelRf, testP) == predict(modelBoosting, testP)
```